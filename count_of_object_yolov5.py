# -*- coding: utf-8 -*-
"""count of object yolov5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rmO5jgFDNKhh10gCir7Ze97hWLf-hPeg
"""

import cv2
import torch

def run(input,output):
  
  model = torch.hub.load('ultralytics/yolov5', 'yolov5s')

  cap = cv2.VideoCapture(input)
  if (cap.isOpened()== False):
    print("Error opening video stream or file")

  ret, frame = cap.read()
  ch, cw, _ = frame.shape
  print("higth:-",ch, "wigth:-",cw)
  
  
  fourcc = cv2.VideoWriter_fourcc(*"XVID")
  fps = 25
  writer = cv2.VideoWriter(output, fourcc, fps, (cw, ch))

  while ret:
    ret, frame = cap.read()
    try:
      image = cv2.resize(frame, (cw, ch))
    except:
      break
    img_m = model(image)
    img_m.pandas().xyxy[0] 
    count_dic = {}
    s = 1
    tt = 20
    if ch >=2000:
      s = 2
      tt = 40
    for n in range(len(img_m.pandas().xyxy[0].value_counts('name'))):
      count_dic[img_m.pandas().xyxy[0].value_counts('name').index[n]] = img_m.pandas().xyxy[0].value_counts('name')[n]
    for n in range(len(img_m.pandas().xyxy[0])):
      for m in count_dic.keys():
          if m == img_m.pandas().xyxy[0].iloc[n]["name"]:
              count_dic[m] = count_dic[m] - 1
              v = count_dic[m]+1
              break
      img = cv2.rectangle(image,(int(img_m.pandas().xyxy[0].iloc[n]["xmin"]),
                           int(img_m.pandas().xyxy[0].iloc[n]["ymax"])),
                      (int(img_m.pandas().xyxy[0].iloc[n]["xmax"]),
                           int(img_m.pandas().xyxy[0].iloc[n]["ymin"])),
                      (0, 0, 255),2) 
      img = cv2.putText(img, m+str(v), 
                    (int(img_m.pandas().xyxy[0].iloc[n]["xmin"]), 
                      int(img_m.pandas().xyxy[0].iloc[n]["ymin"])-5),
                    cv2.FONT_HERSHEY_SIMPLEX, s, (0, 0, 250), 2)
      
    img = cv2.rectangle(img, (int((2/100)*cw),int((2/100)*ch)), (int((20/100)*cw),int((12/100)*ch)), (181, 7, 245), -1)
    t = 0
    for n in range(len(img_m.pandas().xyxy[0].value_counts('name'))):
      t = t + tt
      img = cv2.putText(img,img_m.pandas().xyxy[0].value_counts('name').index[n]+":"+
                       str(img_m.pandas().xyxy[0].value_counts('name')[n]) , 
                        (int((cw/10)/5), int((ch/10)/5)+t), cv2.FONT_HERSHEY_SIMPLEX, s, (255,255,255), 2)
    cv2.imshow("img",img)
    writer.write(img)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

  writer.release()
  cap.release()

input = "/content/drive/MyDrive/assement/test.mp4"

output = "/content/text_output1.mp4"

run(input,output)